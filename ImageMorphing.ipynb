{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb31a22a",
   "metadata": {},
   "source": [
    "# Image Morphing\n",
    "_by Edoardo Maines (mat. 232226) and Davide Modolo (mat. 229297)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ebb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy opencv-contrib-python Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bab553",
   "metadata": {},
   "source": [
    "## Import python libs + our \"resize\"\n",
    "The morph function of opencv needs two images of the exact same size, so we wrote our own library to resize them without cutting pixels (dragging + padding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d91ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 # for facial rec\n",
    "import math # to round\n",
    "import resize # our lib to resize\n",
    "from IPython.display import clear_output #to write animations progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17237915",
   "metadata": {},
   "source": [
    "## Fading\n",
    "The easiest morphing approach is a simple fade between the two images. We start with the first having 100% alpha value and the second with 0%, then at each iteration we decrease the first by an arbitrary 2% and we increase the second by 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d065bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FADING\n",
    "def fading(img1,img2):\n",
    "    for a in range(0, 102, 2):\n",
    "        # calculate current alpha step\n",
    "        alpha_value = a/100\n",
    "        # compute the result image\n",
    "        img3 = Image.blend(img1, img2, alpha_value)\n",
    "        #show the frame\n",
    "        cv2.imshow(\"Fade\", np.array(img3))\n",
    "        clear_output(wait=True)\n",
    "        print('Alpha value: ', round(alpha_value,2))\n",
    "        cv2.waitKey(25)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8561ba",
   "metadata": {},
   "source": [
    "## Morphing Function\n",
    "OpenCV has a warp function, that takes 3 points of the first image, 2 points of the second image and the result is a warped second image based on the first. In this function, we compute each individual step, getting the animation as result.\n",
    "The idea has been taken by this youtube video: https://www.youtube.com/watch?v=56rxZGU7JxQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphImage(img1, img1points, img2, img2points):\n",
    "    n_points = 3\n",
    "    steps = 100\n",
    "    frame = 1.0/steps\n",
    "    # create empty lists\n",
    "    pts11 = np.zeros((n_points, 2), np.float32)\n",
    "    pts22 = np.zeros((n_points, 2), np.float32)\n",
    "    pts1 = np.zeros((n_points, 2), np.float32)\n",
    "    pts2 = np.zeros((n_points, 2), np.float32)\n",
    "    # fill the list of points for each image\n",
    "    for i in range(n_points):\n",
    "        pts1[i] = img1points[i]\n",
    "        pts2[i] = img2points[i]\n",
    "    # for each frame\n",
    "    for i in range(steps):\n",
    "        # for each of 3 points\n",
    "        for j in range(n_points):\n",
    "            # some math to calclate the distance\n",
    "            disx = (pts1[j, 0] - pts2[j, 0])*-1\n",
    "            disy = (pts1[j, 1] - pts2[j, 1])*-1\n",
    "            \n",
    "            # calculate movements of each point of each images\n",
    "            movex1 = (disx/steps) * (i+1)\n",
    "            movey1 = (disy/steps) * (i+1)\n",
    "            \n",
    "            movex2 = disx-movex1\n",
    "            movey2 = disy-movey1\n",
    "            \n",
    "            # perform the \"movement\"\n",
    "            pts11[j, 0] = pts1[j, 0] + movex1\n",
    "            pts11[j, 1] = pts1[j, 1] + movey1\n",
    "\n",
    "            pts22[j, 0] = pts2[j, 0] - movex2\n",
    "            pts22[j, 1] = pts2[j, 1] - movey2\n",
    "            \n",
    "        # after computing the movement of each of the three points we get the matrix\n",
    "        mat1 = cv2.getAffineTransform(pts1, pts11)\n",
    "        mat2 = cv2.getAffineTransform(pts2, pts22)\n",
    "        # we compute the \"warping step\"\n",
    "        dst1 = cv2.warpAffine(\n",
    "            img1, mat1, (img1.shape[1], img1.shape[0]), None, None, cv2.BORDER_REPLICATE)\n",
    "\n",
    "        dst2 = cv2.warpAffine(\n",
    "            img2, mat2, (img1.shape[1], img1.shape[0]), None, None, cv2.BORDER_REPLICATE)\n",
    "        # we sum up the result of the two pictures\n",
    "        result = cv2.addWeighted(dst1, 1-(frame*(i)), dst2, frame*(i+1), 0)\n",
    "        # we show the frame\n",
    "        cv2.imshow(\"Morph\", result)\n",
    "        clear_output(wait=True)\n",
    "        print('Morphing Steps: ', i+1)\n",
    "        if(i == steps-1):\n",
    "            cv2.waitKey()\n",
    "        else:\n",
    "            cv2.waitKey(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f52f0",
   "metadata": {},
   "source": [
    "## Morphing by Point-picking\n",
    "We ask the user to pick three points in each image (with coherent order) and then we call the morphing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedb619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def picPoint(event, x, y, flags, param):\n",
    "    global point\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # when mouse left clicked, save its coordinates\n",
    "        point = (float(x), float(y))\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "def manualPick(img1, img2):\n",
    "    n_points = 3\n",
    "    # initialize variables to save the picked points\n",
    "    img1points = []\n",
    "    img2points = []\n",
    "    for i in range(n_points):\n",
    "        # show first image\n",
    "        cv2.imshow('First Image', img1)\n",
    "        # recall the function when mouse clicked\n",
    "        cv2.setMouseCallback('First Image', picPoint)\n",
    "        cv2.waitKey(0)\n",
    "        # append the clicked point to the list\n",
    "        img1points.append(point)\n",
    "        # repeat for image 2\n",
    "        cv2.imshow('Second Image', img2)\n",
    "        cv2.setMouseCallback('Second Image', picPoint)\n",
    "        cv2.waitKey(0)\n",
    "        img2points.append(point)\n",
    "    # return picked points\n",
    "    return img1points, img2points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8158482",
   "metadata": {},
   "source": [
    "## Autopicking points\n",
    "If the two images are not faces, we thought about a way to pick 3 points according to some \"similarity\" between them.\n",
    "First we subdivide the first image in a grid (in this case 10x10), then we check for each \"cell\" the most similar point in the second image.\n",
    "We save every max-similarity point in a list, only if\n",
    "- there is not another similarity point in the same region \n",
    "- the points in the two images are not too far between\n",
    "- only if under 100%, because otherwise il will probably be in the start/end/top/bottom padding\n",
    "\n",
    "If no similarity point is found, we arbitrarely assign them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the distance between two points\n",
    "def distance(pt1, pt2):\n",
    "    first_diff = (pt2[0]-pt1[0])**2\n",
    "    second_diff = (pt2[1]-pt1[1])**2\n",
    "    return round(math.sqrt(first_diff+second_diff))\n",
    "\n",
    "def autoPick(img1, img2):\n",
    "    # decide in how many rows and columns we want to subdivide our first image\n",
    "    k_rows = 10\n",
    "    k_cols = 10\n",
    "    # calculate each \"cell\" width and height\n",
    "    k_width = round(img1.shape[1]/k_rows)\n",
    "    k_height = round(img1.shape[0]/k_cols)\n",
    "\n",
    "    interesting_points = []\n",
    "\n",
    "    for i in range(k_rows):\n",
    "        for j in range(k_cols):\n",
    "            # crop the current cell from the first image\n",
    "            cell = img1[j*k_height:(j+1)*k_height, i*k_width:(i+1)*k_width]\n",
    "            # find the maximum similarity with opencv\n",
    "            result = cv2.matchTemplate(img2, cell, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "            # calculate the center of the current cell relative to the full image1\n",
    "            cell_center = (round(k_width*(1+2*i)/2), round(k_height*(1+2*j)/2))\n",
    "\n",
    "            # first we check if the two points are a bit close\n",
    "            # and if the similarity is not 100% (otherwise it could be just padding)\n",
    "            distance_threshold = img1.shape[1]/5*2 # it's like an hyperparameter\n",
    "            if(distance(cell_center, max_loc) < (distance_threshold) and max_val < 100):\n",
    "                add = True\n",
    "                # now we check if there already is another close point in the list of\n",
    "                # chosen possible points\n",
    "                threshold_new_point = img1.shape[1]/2 # another hyperparameter\n",
    "                for point in interesting_points:\n",
    "                    if distance(point[1], cell_center) < threshold_new_point:\n",
    "                        add = False\\\n",
    "                # then, if there is not, we add the center point to the possible points to\n",
    "                # select for morphing\n",
    "                if add:\n",
    "                    interesting_points.append(\n",
    "                        (round(max_val, 3), cell_center, max_loc))\n",
    "                # resulting in a list (their_similarity, point_img1, point_img2)\n",
    "    \n",
    "    # we then sort by similarity reversed to have first the points with higher similarity\n",
    "    interesting_points.sort(reverse=True)\n",
    "    \n",
    "    n_points = 3\n",
    "    # if for any reason there aren't at least three points in the list, we arbitrarely chose them\n",
    "    if(len(interesting_points) < (n_points)):\n",
    "        print('Not enough points')\n",
    "        interesting_points = [(1, (0, 0), (10, 10)), (1, (img1.shape[0]/2, img1.shape[0]/2),\n",
    "                                                      (img2.shape[0]/2, img2.shape[0]/2)), (1, (300, 20), (300, 100))]\n",
    "    # we pick the first three points of the list to morph, ordered by the first points\n",
    "    interesting_points = interesting_points[:n_points]\n",
    "    interesting_points.sort(key=lambda x: x[1][1])\n",
    "    # we create the list of points in the format our morphing function wants\n",
    "    img1points = np.zeros((n_points, 2), np.float32)\n",
    "    img2points = np.zeros((n_points, 2), np.float32)\n",
    "    for i in range(n_points):\n",
    "        img1points[i] = interesting_points[i][1]\n",
    "        img2points[i] = interesting_points[i][2]\n",
    "    # return selected points   \n",
    "    return img1points,img2points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252df3e5",
   "metadata": {},
   "source": [
    "## Face Detection\n",
    "Disclaimer: **dlib** is hard to install correctly, this is why it doesn't appear in the first block (installing dependencies)\n",
    "\n",
    "We arbitrarely decided to take points 38 (left eye), 45 (right eye) and 67 (lower mouth lip) of the two recognized faces.\n",
    "\n",
    "<img src=\"resources/landmarks.png\" style=\"zoom:25%\" border=\"0px\" position=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c6b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "def facePoints(img1, img2):\n",
    "    img1 = np.array(img1)\n",
    "    img2 = np.array(img2)\n",
    "    # load the face detector\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    landmark_detector = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    # initialize lists of points we want to use for morphing\n",
    "    points1 = []\n",
    "    points2 = []\n",
    "    # convert to gray and detect\n",
    "    gray = cv2.cvtColor(src=img1, code=cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    # if in the fist image there is no face, call the autopick function\n",
    "    if(len(faces) < 1):\n",
    "        return autoPick(img1, img2)\n",
    "    \n",
    "    for _, d in enumerate(faces):\n",
    "        # select points 38, 45 and 67 from the first picture\n",
    "        landmarks = landmark_detector(img1, d)\n",
    "        x = landmarks.part(38).x\n",
    "        y = landmarks.part(38).y\n",
    "        points1.append((x,y))\n",
    "        x = landmarks.part(45).x\n",
    "        y = landmarks.part(45).y\n",
    "        points1.append((x,y))\n",
    "        x = landmarks.part(67).x\n",
    "        y = landmarks.part(67).y\n",
    "        points1.append((x,y))\n",
    "        break\n",
    "    # convert to gray and detect\n",
    "    gray = cv2.cvtColor(src=img2, code=cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    # if in the second image there is no face, call the autopick function\n",
    "    if(len(faces) < 1):\n",
    "        return autoPick(img1, img2)\n",
    "    \n",
    "    for k, d in enumerate(faces):\n",
    "        # select points 38, 45 and 67 from the second picture\n",
    "        landmarks = landmark_detector(img2, d)\n",
    "        x = landmarks.part(38).x\n",
    "        y = landmarks.part(38).y\n",
    "        points2.append((x,y))\n",
    "        x = landmarks.part(45).x\n",
    "        y = landmarks.part(45).y\n",
    "        points2.append((x,y))\n",
    "        x = landmarks.part(67).x\n",
    "        y = landmarks.part(67).y\n",
    "        points2.append((x,y))\n",
    "        break\n",
    "        \n",
    "    return points1, points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce424b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open(\"images/pic1.jpg\")\n",
    "img2 = Image.open(\"images/pic2.jpg\")\n",
    "img1, img2 = resize.normalizeImages(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e33ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FADING - requires two PIL images\n",
    "fading(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb80ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy for the functions below\n",
    "img1 = np.array(img1)\n",
    "img2 = np.array(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08951c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTO PICK\n",
    "img1points, img2points = autoPick(img1, img2)\n",
    "morphImage(img1, img1points, img2, img2points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bce280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL PICK\n",
    "img1points, img2points = manualPick(img1, img2)\n",
    "morphImage(img1, img1points, img2, img2points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43823414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FACE REC\n",
    "img1points, img2points = facePoints(img1, img2)\n",
    "morphImage(img1, img1points, img2, img2points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
